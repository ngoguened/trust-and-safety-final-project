{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645154d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f869e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.read_csv(\"test-data/preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b690dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Fold 1/5 ---\n",
      "--- Processing Fold 2/5 ---\n",
      "--- Processing Fold 3/5 ---\n",
      "--- Processing Fold 4/5 ---\n",
      "--- Processing Fold 5/5 ---\n",
      "Individual F1-Scores: [0.875, 0.8666666666666667, 0.8148148148148148, 0.9333333333333333, 0.782608695652174]\n",
      "Mean F1-Score across 5 folds: 0.8545\n",
      "Standard Deviation of F1-Score: 0.0520\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_text = data_preprocessed[\"cleaned_text\"]\n",
    "y_target = data_preprocessed[\"target\"]\n",
    "\n",
    "N_SPLITS = 5 \n",
    "kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "M = 0.001 # Minimum frequency threshold\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_text, y_target)):\n",
    "    print(f\"--- Processing Fold {i+1}/{N_SPLITS} ---\")\n",
    "    \n",
    "    X_train_text, X_val_text = X_text.iloc[train_index], X_text.iloc[val_index]\n",
    "    y_train, y_val = y_target.iloc[train_index], y_target.iloc[val_index]\n",
    "\n",
    "    vectorizer = CountVectorizer(binary=True, min_df=M)\n",
    "    \n",
    "    X_train_features = vectorizer.fit_transform(X_train_text)\n",
    "    X_val_features = vectorizer.transform(X_val_text)\n",
    "    \n",
    "    logreg_l2 = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=42)\n",
    "    model_logreg_l2 = logreg_l2.fit(X_train_features, y_train)\n",
    "    \n",
    "    y_pred = model_logreg_l2.predict(X_val_features)\n",
    "    fold_f1 = f1_score(y_true=y_val, y_pred=y_pred)\n",
    "    f1_scores.append(fold_f1)\n",
    "\n",
    "print(f\"Individual F1-Scores: {f1_scores}\")\n",
    "print(f\"Mean F1-Score across {N_SPLITS} folds: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Standard Deviation of F1-Score: {np.std(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d56269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'models/trained_logistic_regression_model.pkl'\n",
    "vectorizer_filename = 'models/trained_count_vectorizer.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model_logreg_l2, file)\n",
    "\n",
    "with open(vectorizer_filename, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
